# ğŸ™ï¸ Hierarchical Voice Pathology Detection System

A deep learning-based system for detecting and classifying voice pathologies using speech signals and electroglottography (EGG) data. The system employs a two-stage hierarchical approach: first detecting healthy vs. pathological voices, then classifying the type of pathology.

## ğŸ“‹ Overview

This project implements a comprehensive pipeline for voice pathology analysis:

- **Stage 1 (Detection)**: Binary classification (Healthy vs. Pathological)
- **Stage 2 (Diagnosis)**: Multi-class classification of pathology types
  - Structural/Inflammatory (Laryngitis + Kontaktpachydermie)
  - Hyperfunctional (Hyperfunktionelle Dysphonie)
  - Neurological (Rekurrensparese)

## ğŸ—ï¸ System Architecture

### Feature Extraction
- **Handcrafted Features**: MFCC, LPC, pitch, jitter, shimmer, HNR, energy, ZCR, spectral slope
- **Deep Features**: Fine-tuned ResNet18 on mel spectrograms (both speech and EGG signals)
- **Multi-modal Fusion**: Combination of handcrafted + speech CNN + EGG CNN features

### Classification Model
- Two-stage hierarchical MLP (Multi-Layer Perceptron)
- Patient-level 80/20 train/test split to prevent data leakage
- Early stopping with validation monitoring

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- FFmpeg (for audio conversion)
- CUDA-capable GPU (optional, but recommended for ResNet training)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/voice-pathology-detection.git
cd voice-pathology-detection
```

2. **Create virtual environment**
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Install FFmpeg**
- **Ubuntu/Debian**: `sudo apt-get install ffmpeg`
- **macOS**: `brew install ffmpeg`
- **Windows**: Download from [ffmpeg.org](https://ffmpeg.org/download.html)

## ğŸ“‚ Project Structure

```
voice-pathology-detection/
â”œâ”€â”€ dataset/                          # Raw dataset folder (not included)
â”‚   â”œâ”€â”€ healthy/
â”‚   â”œâ”€â”€ Laryngitis/
â”‚   â”œâ”€â”€ Hyperfunktionelle Dysphonie/
â”‚   â”œâ”€â”€ Kontaktpachydermie/
â”‚   â””â”€â”€ Rekurrensparese/
â”œâ”€â”€ data.py                          # Dataset preparation & WAV conversion
â”œâ”€â”€ feature_extraction.py            # Handcrafted features & spectrograms
â”œâ”€â”€ resnet18_deep_features.py       # Deep feature extraction with ResNet18
â”œâ”€â”€ fuse_data.py                    # Feature fusion & label grouping
â”œâ”€â”€ final.py                        # Hierarchical MLP training & evaluation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”„ Pipeline Execution

Run the scripts in this order:

### 1. Data Preparation
```bash
python data.py
```
- Converts audio files to WAV format
- Extracts patient metadata (age, disease)
- Creates 80/20 train/test split at patient level
- Outputs: `Final_5Class_Dataset/`

### 2. Feature Extraction
```bash
python feature_extraction.py
```
- Extracts handcrafted audio features
- Generates mel spectrograms for speech and EGG signals
- Outputs: `Extracted_Features/`

### 3. Deep Feature Extraction
```bash
python resnet18_deep_features.py
```
- Fine-tunes ResNet18 on mel spectrograms
- Extracts deep features from penultimate layer
- Trains separate models for speech and EGG
- Outputs: `Deep_Features/`

### 4. Feature Fusion
```bash
python fuse_data.py
```
- Merges handcrafted + speech CNN + EGG CNN features
- Groups labels (1 & 3 â†’ Structural/Inflammatory)
- Outputs: `fused_dataset_4class.csv`

### 5. Hierarchical Training & Evaluation
```bash
python final.py
```
- Trains two-stage hierarchical classifier
- Evaluates on three levels:
  - Level 1: Detection (Healthy vs. Sick)
  - Level 2: Diagnosis (Pathology type)
  - Overall: End-to-end system accuracy
- Generates confusion matrices

## ğŸ“Š Dataset Format

Place your dataset in a `dataset/` folder with this structure:

```
dataset/
â”œâ”€â”€ healthy/
â”‚   â”œâ”€â”€ overview.csv
â”‚   â””â”€â”€ [patient audio files]
â”œâ”€â”€ Laryngitis/
â”‚   â”œâ”€â”€ overview.csv
â”‚   â””â”€â”€ [patient audio files]
â””â”€â”€ ...
```

Each `overview.csv` should contain:
- `AufnahmeID`: Patient ID
- `Geburtsdatum`: Birth date (YYYY-MM-DD)
- `AufnahmeDatum`: Recording date (YYYY-MM-DD)

## ğŸ¯ Class Mapping

| Original Label | Disease | Grouped Label | Class Name |
|---------------|---------|---------------|------------|
| 0 | Healthy | 0 | Healthy |
| 1 | Laryngitis | 1 | Structural/Inflammatory |
| 2 | Hyperfunktionelle Dysphonie | 2 | Hyperfunctional |
| 3 | Kontaktpachydermie | 1 | Structural/Inflammatory |
| 4 | Rekurrensparese | 3 | Neurological |

## ğŸ“ˆ Results

The system outputs three confusion matrices:

- `cm_level1_detection.png` - Binary detection performance
- `cm_level2_diagnosis.png` - Pathology classification (on sick patients only)
- `cm_overall.png` - End-to-end system performance

## âš™ï¸ Configuration

Key parameters can be modified in each script:

**data.py**
- `RANDOM_STATE = 42` - Reproducibility seed
- `DATASET_FOLDER_NAME = "dataset"` - Input folder

**feature_extraction.py**
- `SR = 16000` - Sampling rate
- `N_MFCC` - Number of MFCC coefficients

**resnet18_deep_features.py**
- `EPOCHS = 7` - Fine-tuning epochs
- `BATCH_SIZE = 16` - Training batch size
- `NUM_CLASSES = 4` - After grouping

**final.py**
- `EPOCHS = 100` - MLP training epochs
- `LR = 0.001` - Learning rate
- `PATIENCE = 20` - Early stopping patience

